# Script principal que executa toda a pipeline de carga e roda TUDO em ordem:
# 1. Carrega DimTempo
# 2. Carrega DimLocalidade
# 3. Carrega FatoDesmatamento
# 4. Mostra logs de quantos registros foram inseridos
# 5. Faz checagens b√°sicas (tem dados? tem erros?)

import sys
from datetime import datetime
from pathlib import Path

# Importa as fun√ß√µes de carga
from utils import configurar_logs, conectar_banco, contar_registros_tabela
from load_dim_tempo import carregar_dim_tempo
from load_dim_localidade import carregar_dim_localidade
from load_fato_desmatamento import carregar_fato_desmatamento


# Define o caminho raiz do projeto (a pasta que cont√©m 'src', 'data', etc.)
PROJECT_ROOT = Path(__file__).parent.parent.parent


def validar_arquivos(caminho_csv):
    """
    Valida se todos os arquivos necess√°rios existem antes de come√ßar

    Args:
        caminho_csv: Caminho para o arquivo Silver

    Returns:
        True se tudo OK, False se houver problema
    """
    import logging

    caminho_silver = Path(caminho_csv)

    if not caminho_silver.exists():
        logging.error(f"‚ùå ERRO: Arquivo Silver n√£o encontrado!")
        logging.error(f"   Caminho esperado: {caminho_silver.absolute()}")
        return False

    logging.info(f"‚úÖ Arquivo Silver encontrado: {caminho_silver}")

    return True


def validar_integridade_dados(caminho_db):
    """
    Faz checagens b√°sicas de integridade dos dados carregados

    Args:
        caminho_db: Caminho para o banco de dados
    """
    import logging

    logging.info("=" * 60)
    logging.info("üîç VALIDANDO INTEGRIDADE DOS DADOS")
    logging.info("=" * 60)

    conexao = conectar_banco(caminho_db)
    cursor = conexao.cursor()

    # Checa se h√° registros em todas as tabelas
    tabelas = ['DimTempo', 'DimLocalidade', 'FatoDesmatamento']
    todas_ok = True

    for tabela in tabelas:
        count = contar_registros_tabela(conexao, tabela)

        if count > 0:
            logging.info(f"   ‚úÖ {tabela}: {count} registros")
        else:
            logging.error(f"   ‚ùå {tabela}: VAZIA!")
            todas_ok = False

    # Checa integridade referencial (FKs)
    logging.info("")
    logging.info("üîó Checando integridade referencial...")

    # Checa FKs de tempo
    cursor.execute("""
        SELECT COUNT(*) 
        FROM FatoDesmatamento f
        LEFT JOIN DimTempo d ON f.id_tempo = d.id_tempo
        WHERE d.id_tempo IS NULL
    """)
    fks_tempo_quebradas = cursor.fetchone()[0]

    if fks_tempo_quebradas == 0:
        logging.info(f"   ‚úÖ Todas as FKs de tempo est√£o corretas")
    else:
        logging.error(f"   ‚ùå {fks_tempo_quebradas} FKs de tempo quebradas!")
        todas_ok = False

    # Checa FKs de localidade
    cursor.execute("""
        SELECT COUNT(*) 
        FROM FatoDesmatamento f
        LEFT JOIN DimLocalidade d ON f.id_localidade = d.id_localidade
        WHERE d.id_localidade IS NULL
    """)
    fks_local_quebradas = cursor.fetchone()[0]

    if fks_local_quebradas == 0:
        logging.info(f"   ‚úÖ Todas as FKs de localidade est√£o corretas")
    else:
        logging.error(f"   ‚ùå {fks_local_quebradas} FKs de localidade quebradas!")
        todas_ok = False

    # Checa se h√° valores nulos na fato
    cursor.execute("""
        SELECT COUNT(*) 
        FROM FatoDesmatamento
        WHERE area_km IS NULL OR area_km = 0
    """)
    areas_invalidas = cursor.fetchone()[0]

    if areas_invalidas == 0:
        logging.info(f"   ‚úÖ Todas as √°reas t√™m valores v√°lidos")
    else:
        logging.warning(f"   ‚ö†Ô∏è {areas_invalidas} registros com √°rea nula ou zero")

    conexao.close()

    if todas_ok:
        logging.info("")
        logging.info("‚úÖ INTEGRIDADE DOS DADOS: OK")
    else:
        logging.error("")
        logging.error("‚ùå PROBLEMAS DE INTEGRIDADE ENCONTRADOS!")

    logging.info("=" * 60)

    return todas_ok


def executar_pipeline(caminho_csv, caminho_db):
    """
    Executa toda a pipeline de carga do Data Warehouse

    Args:
        caminho_csv: Caminho para o arquivo Silver
        caminho_db: Caminho para o banco de dados

    Returns:
        True se sucesso, False se houver erro
    """
    import logging

    # Marca hora de in√≠cio
    hora_inicio = datetime.now()

    logging.info("")
    logging.info("‚ïî" + "=" * 58 + "‚ïó")
    logging.info("‚ïë" + " " * 10 + "PIPELINE DE CARGA - DATA WAREHOUSE" + " " * 13 + "‚ïë")
    logging.info("‚ïë" + " " * 15 + "An√°lise de Desmatamento" + " " * 20 + "‚ïë")
    logging.info("‚ïö" + "=" * 58 + "‚ïù")
    logging.info("")
    logging.info(f"üïê In√≠cio: {hora_inicio.strftime('%Y-%m-%d %H:%M:%S')}")
    logging.info("")

    try:
        # ETAPA 1: Valida√ß√£o dos arquivos
        logging.info("üìã ETAPA 1/4: Validando arquivos necess√°rios...")
        if not validar_arquivos(caminho_csv):
            return False
        logging.info("")

        # ETAPA 2: Carga das dimens√µes
        logging.info("üìã ETAPA 2/4: Carregando dimens√µes...")
        logging.info("")

        # Carrega DimTempo
        registros_tempo = carregar_dim_tempo(caminho_csv, caminho_db)
        logging.info("")

        # Carrega DimLocalidade
        registros_localidade = carregar_dim_localidade(caminho_csv, caminho_db)
        logging.info("")

        # ETAPA 3: Carga da tabela fato
        logging.info("üìã ETAPA 3/4: Carregando tabela fato...")
        logging.info("")

        registros_fato = carregar_fato_desmatamento(caminho_csv, caminho_db)
        logging.info("")

        # ETAPA 4: Valida√ß√£o da integridade
        logging.info("üìã ETAPA 4/4: Validando integridade dos dados...")
        logging.info("")

        integridade_ok = validar_integridade_dados(caminho_db)
        logging.info("")

        # Calcula tempo de execu√ß√£o
        hora_fim = datetime.now()
        tempo_execucao = hora_fim - hora_inicio

        # Resumo final
        logging.info("‚ïî" + "=" * 58 + "‚ïó")
        logging.info("‚ïë" + " " * 18 + "RESUMO DA EXECU√á√ÉO" + " " * 21 + "‚ïë")
        logging.info("‚ïö" + "=" * 58 + "‚ïù")
        logging.info("")
        logging.info(f"‚úÖ Pipeline executada com sucesso!")
        logging.info("")
        logging.info("üìä Registros processados:")
        logging.info(f"   ‚Ä¢ DimTempo: {registros_tempo} novos registros")
        logging.info(f"   ‚Ä¢ DimLocalidade: {registros_localidade} novos registros")
        logging.info(f"   ‚Ä¢ FatoDesmatamento: {registros_fato} novos registros")
        logging.info("")
        logging.info(f"üïê Tempo de execu√ß√£o: {tempo_execucao.total_seconds():.2f} segundos")
        logging.info(f"üìÅ Banco de dados: {Path(caminho_db).absolute()}")
        logging.info(f"üìù Log salvo em: logs/pipeline_run.log")
        logging.info("")

        if integridade_ok:
            logging.info("‚úÖ Integridade dos dados: OK")
        else:
            logging.warning("‚ö†Ô∏è Aten√ß√£o: Alguns problemas de integridade foram detectados")

        logging.info("")
        logging.info("=" * 60)

        return True

    except Exception as e:
        logging.error("")
        logging.error("=" * 60)
        logging.error("‚ùå ERRO DURANTE A EXECU√á√ÉO DA PIPELINE")
        logging.error(f"   {str(e)}")
        logging.error("=" * 60)
        logging.error("")

        import traceback
        logging.error("Detalhes do erro:")
        logging.error(traceback.format_exc())

        return False


if __name__ == "__main__":
    # Configura o sistema de logs
    logger = configurar_logs()

    # Executa a pipeline
    caminho_csv_silver = PROJECT_ROOT / 'data' / 'silver' / 'deforestation_silver_layer.csv'
    caminho_banco_dados = PROJECT_ROOT / 'db' / 'desmatamento.db'

    sucesso = executar_pipeline(caminho_csv=caminho_csv_silver,
                                caminho_db=caminho_banco_dados)

    # Retorna c√≥digo de sa√≠da apropriado
    sys.exit(0 if sucesso else 1)